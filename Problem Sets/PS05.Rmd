---
title: "PS05"
author: "Emily Han"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(MASS)
library(huxtable)
library(stargazer)
library(caret)
library(nnet)
library(marginaleffects)
```

## 2. Ordered categorical responses.
For this exercise you will need to load the file drury_jpr_data.csv
```{r}
dat <- read.csv("./data/drury_jpr_data.csv")
```

### a.
Using Drury’s data, use an ordered logit regression to evaluate the success of economic sanctions (result). Fit two models. The first model should include the (log) GNP ratio (gnprat), amount of trade (trade), target GNP cost (tarcst), sender cost (cost), and whether there is a cooperative relationship (coop). The second model should leave out two of the covariates of your choosing. Present the models in a well-formatted table and then evaluate which model is preferred on an in-sample and out-of-sample fit basis. You can find the polr() function in the MASS libray. The rms library also has ordered logit functionality.


```{r}
mod1 <- polr(as.ordered(result) ~ log(gnprat) + trade + tarcst + cost + coop, 
             data = dat, method = "logistic", Hess = T)

mod2 <- polr(as.ordered(result) ~ log(gnprat) + cost + coop, 
             data = dat, method = "logistic", Hess = T)
```





```{r}
#Models' summary

huxreg(list("Full Model" = mod1, "Simple Model" = mod2))
```

```{r}
dat$result <- as.ordered(dat$result)

# Split data into training (80%) and testing (20%)
trainIndex <- createDataPartition(dat$result, p = 0.8, list = FALSE)
trainData <- dat[trainIndex, ]
testData <- dat[-trainIndex, ]

# Define training control for repeated cross-validation
train_control <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation

# Train ordered logit model using caret with polr
model1 <- train(result ~ log(gnprat) + trade + tarcst + cost + coop, 
                data = trainData, 
                method = "polr",
                trControl = train_control)

model2 <- train(result ~ log(gnprat) + cost + coop,  # Without trade and tarcst
                data = trainData, 
                method = "polr",
                trControl = train_control)

# Make predictions on the test set
pred1_probs <- predict(model1, testData, type = "prob")
pred2_probs <- predict(model2, testData, type = "prob")

# Convert probabilities to predicted classes
pred1_class <- predict(model1, testData)
pred2_class <- predict(model2, testData)

# Compute accuracy
acc1 <- confusionMatrix(pred1_class, testData$result)$overall["Accuracy"]
acc2 <- confusionMatrix(pred2_class, testData$result)$overall["Accuracy"]

# Print results
cat("Model 1 Accuracy:", acc1, "\n")
cat("Model 2 Accuracy:", acc2, "\n")
```


Although the out-of-sample fit suggests that the models are very similar in performance, the in-sample metrics suggests that full model is the better fit as it has higher log-likehood and lower AIC value. 




### b.
For the better performing of your two models, choose a particular predictor variable and develop a set of scenarios to interpret how that variable relates to the outcome. Be sure to clearly state what your quantity of interest is. Construct a graphical display that presents this interpretive quantity; be sure to include some estimate of your uncertainty around this quantity. In constructing this, use explicit code similar to that on p. 151.

```{r}
X.low <- cbind(
  log_gnprat = mean(log(dat$gnprat)), 
  trade = mean(dat$trade), 
  tarcst = mean(dat$tarcst),
  cost = median(dat$cost),  
  coop = 1 
)

X.high <- cbind(
  log_gnprat = mean(log(dat$gnprat)), 
  trade = mean(dat$trade), 
  tarcst = mean(dat$tarcst),
  cost = median(dat$cost),  
  coop = 4 
)

```

```{r}
# Simulate coefficient draws for uncertainty estimation
draws <- mvrnorm(1000, c(coef(mod1), mod1$zeta), solve(mod1$Hessian))
B <- draws[, 1:length(coef(mod1))]  # Extract coefficients
Taus <- draws[, (length(coef(mod1)) + 1):ncol(draws)]  # Extract cutpoints

# Predicted probabilities for ⁠ coop = 1 ⁠ and ⁠ coop = 4 ⁠
# Compute predicted probabilities for each class
pi.class1.sc1 <- plogis(Taus[, 1] - B %*% t(X.low))  # Pr(Y = 1)
pi.class1.sc2 <- plogis(Taus[, 1] - B %*% t(X.high))

pi.class2.sc1 <- plogis(Taus[, 2] - B %*% t(X.low)) - plogis(Taus[, 1] - B %*% t(X.low))  # Pr(Y = 2)
pi.class2.sc2 <- plogis(Taus[, 2] - B %*% t(X.high)) - plogis(Taus[, 1] - B %*% t(X.high))

pi.class3.sc1 <- plogis(Taus[, 3] - B %*% t(X.low)) - plogis(Taus[, 2] - B %*% t(X.low))  # Pr(Y = 3)
pi.class3.sc2 <- plogis(Taus[, 3] - B %*% t(X.high)) - plogis(Taus[, 2] - B %*% t(X.high))

pi.class4.sc1 <- 1 - plogis(Taus[, 3] - B %*% t(X.low))  # Pr(Y = 4)
pi.class4.sc2 <- 1 - plogis(Taus[, 3] - B %*% t(X.high))

# Compute first difference in probabilities
fd.class1 <- pi.class1.sc2 - pi.class1.sc1
fd.class2 <- pi.class2.sc2 - pi.class2.sc1
fd.class3 <- pi.class3.sc2 - pi.class3.sc1
fd.class4 <- pi.class4.sc2 - pi.class4.sc1

plot(density(fd.class1, adjust=1.5),
     xlim = c(-0.75, 0.75), ylim = range(density(fd.class1)$y, density(fd.class2)$y,density(fd.class3)$y, density(fd.class4)$y),
     xlab = "Change in Predicted Probability",
     col = "black", bty = "n",
     yaxt = "n", lwd = 2, main = "", ylab = "")

lines(density(fd.class2, adjust=1.5), col=grey(0.5), lwd=2, lty=2)
lines(density(fd.class3, adjust=1.5), col="blue", lwd=2, lty=3)
lines(density(fd.class4, adjust=1.5), col="red", lwd=2, lty=4)

text(x=0.1, y=4, labels="Pr(Category 1 | High Coop) - Pr(Category 1 | Low Coop)", cex=0.6, adj=0)
text(x=0.1, y=6, labels="Pr(Category 2 | High Coop) - Pr(Category 2 | Low Coop)", cex=0.6, adj=0, col=grey(0.5))
text(x=0.1, y=8, labels="Pr(Category 3 | High Coop) - Pr(Category 3 | Low Coop)", cex=0.6, adj=0, col="blue")
text(x=0.1, y=10, labels="Pr(Category 4 | High Coop) - Pr(Category 4 | Low Coop)", cex=0.6, adj=0, col="red")
```

### c

Use the same linear specification as in (b) but fit an OLS model. Is the ordered logit to be preferred over the OLS?

```{r}
dat$result <- as.numeric(dat$result)
lm_model <- lm(result ~ log(gnprat) + trade + tarcst + cost + coop, 
             data = dat)
AIC(lm_model)
AIC(mod1)
logLik(lm_model)
logLik(mod1)
```

Both lower log likelihood and higher AIC value of the OLS suggests that the ordered logit is a better bit over the OLS model. 

### d. 

Use the same linear specification as in (b) but fit the model as a multinomial logit. Evaluate whether the parallel regressions assumption holds for the ordered logit model. The multinom() function in the nnet library fits multinomial logit. You might also consider the mlogit library.

```{r}
mnl_mod <-multinom(as.factor(result) ~  log(gnprat) +trade + tarcst + cost + coop,
                      Hess=T, model=T,data=dat, maxit=200)

```
```{r}
huxreg(list("Ordered Logit Model" = mod1, "Multinominal Model" = mnl_mod))
```








### e. 
Using the scenario you devised in (b), provide an interpretation of the MNL version of the model that you just fit. This time use the marginaleffects library.

```{r}
mfx <- marginaleffects(mnl_mod)
summary(mfx)

```










```{r}
sessionInfo()
```

