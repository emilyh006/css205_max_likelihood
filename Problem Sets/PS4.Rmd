---
title: "PS04 by Emily Han"
output:
  pdf_document: default
  html_document: default
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)


```

## 1. Fearon & Laitin

You will need to download the file flmdw.csv and load it into your workspace. This is the data needed to replicate the analysis in Fearon & Laitin’s 2003 APSR paper. The data are country-year data, but we will be ignoring the time component for the purposes of this exercise.

You will analyze the Fearon & Laitin data on civil war onset, specifically, the binary onset variable.

```{r}
#Loading the dataset
dat <- read.csv("./data/flmdw.csv")
```

### a. Examine the distribution of onset. Is this a “rare event”? What options might you consider?

```{r}
table(dat$onset)
```

### b. Fit at least four models that predict binary onset. Analyze only complete cases and make sure that all three models are fit to the same observations but be careful how you remove NAs

Model 1 should be a logistic regression including only an intercept, GDP per capita (gdpenl), population (lpopl1) and percent mountainous (lmtnest).

```{r}
logit_mod <- glm(onset ~ gdpenl + lpopl1 + lmtnest, family = binomial (link = 'logit'), data = dat)
```

Model 2 should be a probit regression but otherwise identical to model 1.

```{r}
probit_mod <- glm(onset ~ gdpenl + lpopl1 + lmtnest, family = binomial (link = 'probit'), data = dat)
```

Model 3 should be a probit regression that adds a dummy variable for whether a country is an oil exporter (Oil), democracy (polity2l), and religious fractionalization (relfrac).

```{r}
probit_dummy_mod <- glm(onset ~ gdpenl + lpopl1 + lmtnest + Oil + polity2l + relfrac, family = binomial (link = 'probit'), data = dat)
```

Model 4 should be a probit regression that includes an interaction between polity2l and relfrac.

```{r}
probit_inter_mod <- glm(onset ~ gdpenl + lpopl1 + lmtnest + Oil + polity2l + relfrac + (relfrac * polity2l), family = binomial (link = 'probit'), data = dat)

```

```{r}
#Models' summary
library(huxtable)

huxreg(list("Logit Model" = logit_mod, "Probit Model" = probit_mod, "Probit w/ Dummy" = probit_dummy_mod, "Probit w/ Interaction" = probit_inter_mod))
```


### c. Develop ROC plot and separation plots comparing the in-sample fit of your estimated models. The ROCR library may help


```{r}
library(pROC)
library(ROCR)
```


```{r}
predicted_logit <-fitted(logit_mod)
predicted_probit <- fitted(probit_mod)
predicted_probit_dummy <- fitted(probit_dummy_mod) 
predicted_probit_inter <- fitted(probit_inter_mod) 

actual <- as.vector(logit_mod$model$onset)
```


```{r}
pred_logit <- prediction(predicted_logit,actual)
perf_logit <- performance(pred_logit,"tpr","fpr")

pred_probit <- prediction(predicted_probit,actual)
perf_probit <- performance(pred_probit,"tpr","fpr")

pred_probit_dummy <- prediction(predicted_probit_dummy,actual)
perf_probit_dummy <- performance(pred_probit_dummy,"tpr","fpr")

pred_probit_inter <- prediction(predicted_probit_inter,actual)
perf_probit_inter <- performance(pred_probit_inter,"tpr","fpr")
```


```{r}
# Plotting the ROC
par(las=1, bty="n")  
plot(perf_logit, main="ROC plots for competing models", bty="n",lwd=2, col = 'purple')
plot(perf_probit, lwd=2, col= 'lightgreen', add=T)
plot(perf_probit_dummy, lwd=2, col= 'lightblue', add=T)
plot(perf_probit_inter, lwd=2, col= 'red', add=T)
lines(actual,actual, lty="dashed")

legend("bottomright", legend = c("logistic_reg", "probit_reg", "probit_dummy", "probit_inter"), fill = c("purple", "lightgreen", "lightblue", "red"))
```

```{r}
# Seperation Plot 
library(DescTools)
library(separationplot)
```

```{r}
# 
# pred_logit_v <- pred_logit@predictions[[1]]
# pred_probit_v <-pred_probit@predictions[[1]]
# pred_probit_dummy_v <- pred_probit_dummy@predictions[[1]]
# pred_probit_inter_v <- pred_probit_inter@predictions[[1]]
#   
#   
#   
#   
#   
# par(mfrow=c(4,2))
# separationplot(pred_logit_v,actual,
#                heading = "Party-only Model", 
#                height = .50, width=2,
#                lwd1 = 0.9, newplot=F)
# separationplot(pred_probit_v,actual,
#                heading = "Full Model",
#                height = .50, width=2,
#                lwd1 =1, lwd2=1, newplot=F)
# separationplot(pred_probit_dummy_v,actual,
#                heading = "Full Model",
#                height = .50, width=2,
#                lwd1 =1, lwd2=1, newplot=F)
# separationplot(pred_probit_inter_v,actual,
#                heading = "Full Model",
#                height = .50, width=2,
#                lwd1 =1, lwd2=1, newplot=F)

```











### d. Using model 4 and a likelihood ratio test, what is the evidence that we can leave polity2l out of the model entirely? In other words, test the hypothesis that 
.
```{r}
mod5 <- glm(onset ~ gdpenl + lpopl1 + lmtnest + Oil + relfrac, data = dat,
            family = "binomial"(link = "probit"))

ll_ratio <- (logLik(probit_inter_mod) - logLik(mod5))
ll_ratio_stat <- -2 * (ll_ratio)

ll_ratio_stat

```

### e. 
Undertake a 10-fold cross-validation of each of these models. Construct an ROC plot of the out of sample predictive performance of each of the models. To do this you can write code to create the 10 folds or you can try and work with the tools in many R libraries that implement cross-validation. These include: cvTools, caret, tidymodels/resampling. On the basis of this analysis, which model(s) do you prefer?

```{r}
probit_mod <- glm(onset ~ gdpenl + lpopl1 + lmtnest, family = binomial (link = 'probit'), data = dat)
```

Model 3 should be a probit regression that adds a dummy variable for whether a country is an oil exporter (Oil), democracy (polity2l), and religious fractionalization (relfrac).

```{r}
probit_dummy_mod <- glm(onset ~ gdpenl + lpopl1 + lmtnest + Oil + polity2l + relfrac, family = binomial (link = 'probit'), data = dat)
```

Model 4 should be a probit regression that includes an interaction between polity2l and relfrac.

```{r}
probit_inter_mod <- glm(onset ~ gdpenl + lpopl1 + lmtnest + Oil + polity2l + relfrac + (relfrac * polity2l), family = binomial (link = 'probit'), data = dat)

```




```{r}
library(caret)


dat1 <-read.csv("./data/flmdw.csv")
dat1$onset <- as.factor(dat1$onset)
levels(dat1$onset) <- c("no", "yes")
```


```{r}
# Define 10-fold cross-validation
cv_control <- trainControl(method = "cv", number = 10, 
                           classProbs = TRUE, summaryFunction = twoClassSummary, 
                           savePredictions = "final")
```


```{r}
# Train Logit model with 10-fold CV
cv_logit <- train(onset ~ gdpenl + lpopl1 + lmtnest, data = dat1, 
                  method = "glm", family = binomial(link = "logit"), 
                  trControl = cv_control, metric = "ROC")

# Train Probit model with 10-fold CV
cv_probit <- train(onset ~ gdpenl + lpopl1 + lmtnest, data = dat1, 
                   method = "glm", family = binomial(link = "probit"), 
                   trControl = cv_control, metric = "ROC")

# Train Probit model with 10-fold CV
cv_probit_dummy <- train(onset ~ gdpenl + lpopl1 + lmtnest + Oil + polity2l + relfrac,
                         data = dat1, method = "glm", family = binomial(link = "probit"),
                         trControl = cv_control, metric = "ROC")

# Train Probit model with 10-fold CV
cv_probit_inter <- train(onset ~ gdpenl + lpopl1 + lmtnest + Oil + polity2l + relfrac + (relfrac * polity2l), 
                         data = dat1, method = "glm", family = binomial(link = "probit"),
                         trControl = cv_control, metric = "ROC")

# Extract Out-of-Sample ROC Data
roc_logit <- roc(cv_logit$pred$obs, cv_logit$pred$yes)   # Logit model OOS predictions
roc_probit <- roc(cv_probit$pred$obs, cv_probit$pred$yes) # Probit model OOS predictions
roc_probit_dummy <- roc(cv_probit_dummy$pred$obs, cv_probit_dummy$pred$yes)   
roc_probit_inter <- roc(cv_probit_inter$pred$obs, cv_probit_inter$pred$yes)




# Plot ROC Curves for Logit vs Probit (10-Fold CV)
plot(roc_logit, col = "blue", lwd = 3, main = "ROC Curve: Logit vs Probit (10-Fold CV)")
plot(roc_probit, col = "red", lwd = 3, add = TRUE, lty = 2)
plot(roc_probit_dummy, col = "green", lwd = 3, add = TRUE, lty = 2)
plot(roc_probit_inter, col = "purple", lwd = 3, add = TRUE, lty = 2)


# Add legend
legend("bottomright", legend = c("Logit Model", "Probit Model", "Probit with Dummy Model", "Probit with Interaction Model"), 
       col = c("blue", "red", "green", "purple"), lty = c(1, 2), lwd = 3, bty = "n")

# Print AUC values for model comparison
logit_auc <- auc(roc_logit)
probit_auc <- auc(roc_probit)
probit_dummy_auc <- auc(roc_probit_dummy)
probit_inter_auc <- auc(roc_probit_inter)

print(paste("Logit AUC:", round(logit_auc, 3)))
print(paste("Probit AUC:", round(probit_auc, 3)))
print(paste("Probit with Dummy AUC:", round(probit_dummy_auc, 3)))
print(paste("Probit with Interaction AUC:", round(probit_inter_auc, 3)))

```
### f.

Interpret the relationship between civil war onset and democracy in the preferred model. Use a visual presentation of the model predictions and be sure to display the estimation uncertainty around the expected values produced by the model. Be sure to clearly state the scenarios you chose and why. If the best performing model includes the interaction term then provide a plot that interprets that conditional relationship.



```{r}
#Clinton’s vote share 
democracy <- seq(min(dat$polity2l), max(dat$polity2l), by = 0.5)

# Drawing 1000 coefficients 
simulated_betas <- mvrnorm(1000, coef(probit_dummy_mod), vcov(probit_dummy_mod))


onset ~ gdpenl + lpopl1 + lmtnest + Oil + polity2l + relfrac
# Democrat Party
onset_no <- cbind(1, 0, mean(gdpenl), mean(lpopl1) )

# Republican Party
onset_yes <- cbind(1, 1, )


#Calculate predicted probability 
prob_demo <- pnorm(simulated_betas %*% demo)
prob_repub <- pnorm(simulated_betas %*% repub)


prob_demo <- apply(prob_demo, 2, function(x) quantile(x, c(0.025, 0.5, 0.975)))
prob_repub <- apply(prob_repub, 2, function(x) quantile(x, c(0.025, 0.5, 0.975)))

               


```





## Use of ChatGPT and other generative AI tools

I certify that we did not use any LLM or generative AI tool in this assignment!

```{r}
sessionInfo()
```
